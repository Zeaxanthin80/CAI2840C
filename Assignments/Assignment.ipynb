{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5 (Week 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment: Video Processing and Contour Detection Using OpenCV\n",
    "\n",
    "reference:  https://colab.research.google.com/drive/1_FGt6GyViY1BAK2dIpf5DFjpH79zBV5E?usp=sharingLinks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective:**\n",
    "\n",
    "In this assignment, you will gain hands-on experience with OpenCV by building three applications in a Google Colab notebook:\n",
    "\n",
    "1. **Video I/O Application:** Read from and write to a video stream. You can modify or extend the code we used in class.\n",
    "2. **Motion Detection Application:** Develop a motion detection system that explains the concepts of foreground mass (the difference between the background model and the current frame) and erosion (a morphological operation used to remove noise). You should demonstrate erosion on a new video clip.\n",
    "3. **Contour Detection Application:** Write code that identifies and draws contours on an image. For extra credit, extend your solution to detect and draw contours in a video (with a clip that is less than one minute long)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Video I/O Application\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "- **Input:** Use any video file of your choice (or create one, e.g., using your webcam or a synthetic video clip that is less than 1 minute long).\n",
    "- **Processing:** Implement a simple transformation on each frame (this can be as basic as converting to grayscale, overlaying text, or drawing shapes).\n",
    "- **Output:** Write the processed frames to a new video file.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. **Reading the Video:**\n",
    "    - Use cv2.VideoCapture to open the video file.\n",
    "    - Loop through each frame and perform your processing.\n",
    "2. **Processing the Frames:**\n",
    "    - Apply your chosen transformation (for example, add a timestamp overlay or convert to grayscale).\n",
    "3. **Writing the Video:**\n",
    "    - Use cv2.VideoWriter to create an output video file.\n",
    "    - Write the processed frames to this file.\n",
    "\n",
    "Hint: Ensure your output video settings (frame size, codec, and frame rate) match the input video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your video file\n",
    "video_path = \"../Visuals/Main.mp4\"  # Replace with your actual video path\n",
    "\n",
    "# Create a VideoCapture object\n",
    "cap = cv2.VideoCapture(video_path) # 0 is typically the default camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: ../Visuals/Main.mp4\n",
      "Video opened successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Replace this with your actual video path\n",
    "video_path = \"../Visuals/Main.mp4\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(video_path):\n",
    "    print(f\"File exists: {video_path}\")\n",
    "else:\n",
    "    print(f\"File does not exist: {video_path}\")\n",
    "    \n",
    "# Try to open the video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video was opened successfully\n",
    "if cap.isOpened():\n",
    "    print(\"Video opened successfully!\")\n",
    "else:\n",
    "    print(\"Failed to open video.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video dimensions: 640x360\n",
      "Frames per second: 29.97002997002997\n"
     ]
    }
   ],
   "source": [
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(f\"Video dimensions: {frame_width}x{frame_height}\")\n",
    "print(f\"Frames per second: {fps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display\n",
    "import time\n",
    "import base64\n",
    "\n",
    "def play_video_in_notebook(video_path, max_frames=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_delay = 1 / fps\n",
    "    \n",
    "    frame_count = 0\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                print(\"End of video.\")\n",
    "                break\n",
    "                \n",
    "            # Convert frame from BGR (OpenCV format) to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Display the frame\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # Convert to JPEG for display\n",
    "            _, buffer = cv2.imencode('.jpg', frame_rgb)\n",
    "            image_data = base64.b64encode(buffer).decode('utf-8')\n",
    "            \n",
    "            # Display the image\n",
    "            display(Image(data=base64.b64decode(image_data)))\n",
    "            \n",
    "            # Wait to maintain the correct frame rate\n",
    "            time.sleep(frame_delay)\n",
    "            \n",
    "            frame_count += 1\n",
    "            if max_frames is not None and frame_count >= max_frames:\n",
    "                print(f\"Reached maximum frames ({max_frames}).\")\n",
    "                break\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Playback interrupted.\")\n",
    "    finally:\n",
    "        cap.release()\n",
    "\n",
    "# Call the function with your video path\n",
    "# play_video_in_notebook(video_path, max_frames=100)  # Limit to 100 frames for quick testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Motion Detection Application with Foreground Mass and Erosion\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "- **Input:** Use a video clip (less than one minute long) that shows some movement.\n",
    "- **Processing:**\n",
    "    - Create a **background model** from the initial frames.\n",
    "    - Compute the **foreground mass** by taking the difference between the current frame and the background model.\n",
    "    - Apply **erosion** to the foreground mask to remove noise (explain how erosion removes small, isolated noise pixels).\n",
    "- **Output:** Annotate the frames (e.g., draw bounding boxes around detected motion areas) and write the output to a new video file.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. **Background Modeling & Foreground Mass:**\n",
    "2. **Applying Erosion:**\n",
    "3. **Annotation and Video Output:**\n",
    "    - Draw bounding rectangles (or other markers) around the regions of motion detected in the eroded foreground mask.\n",
    "    - Write the annotated frames to a new output video.\n",
    "    \n",
    "Bonus: You can include intermediate visualizations (e.g., display the raw foreground mask vs. the eroded mask) to show the effect of erosion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Contour Detection Application\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    " - **Input:** Use an image that contains distinct shapes (or create one with simple geometric shapes).\n",
    " - **Processing:**\n",
    "    - Convert the image to grayscale and threshold it to create a binary image.\n",
    "    - Use cv2.findContours to detect the contours.\n",
    "    - Use cv2.drawContours to overlay the detected contours on the original image.\n",
    "- **Output:** Display the resulting image with contours drawn.\n",
    "- **Bonus:** Extend your code to process a video stream frame-by-frame, drawing contours on each frame.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. **Image Preprocessing:**\n",
    "    - Load the image and convert it to grayscale.\n",
    "    - Apply a binary threshold to segment the shapes.\n",
    "2. **Contour Detection:**\n",
    "    - Use cv2.findContours with appropriate retrieval and approximation modes.\n",
    "    - Explain the output: a list of contours and (optionally) a hierarchy that indicates relationships between contours.\n",
    "3. **Drawing the Contours:**\n",
    "    - Use cv2.drawContours to overlay the detected contours onto the image.\n",
    "    - Display the final image.\n",
    "4. **(Bonus) Video Contour Detection:**\n",
    "    - Modify your code from Part 1 to process a video.\n",
    "    - For each frame, detect contours and draw them before writing the frame to an output video file.\n",
    "\n",
    "Hint: Choose a short video clip (under one minute) to ensure quick processing and review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
